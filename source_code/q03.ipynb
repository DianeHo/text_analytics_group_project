{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Naive Bayes for Word2Vec (it does not support negative values).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Performance:\n",
      "Feature Model                              TF-IDF\n",
      "Classifier                                    SVM\n",
      "Mean Train Accuracy (CV)                 0.975253\n",
      "Test Accuracy                            0.986511\n",
      "Spam Recall                              0.926174\n",
      "Confusion Matrix            [[959, 4], [11, 138]]\n",
      "Name: 7, dtype: object\n",
      "\n",
      "All Model Results:\n",
      "   Feature Model           Classifier  Mean Train Accuracy (CV)  \\\n",
      "0   Bag of Words        Decision Tree                  0.920360   \n",
      "1   Bag of Words          Naive Bayes                  0.970754   \n",
      "2   Bag of Words  Logistic Regression                  0.977278   \n",
      "3   Bag of Words                  SVM                  0.972553   \n",
      "4         TF-IDF        Decision Tree                  0.930259   \n",
      "5         TF-IDF          Naive Bayes                  0.956130   \n",
      "6         TF-IDF  Logistic Regression                  0.951856   \n",
      "7         TF-IDF                  SVM                  0.975253   \n",
      "8       Word2Vec        Decision Tree                  0.915411   \n",
      "9       Word2Vec  Logistic Regression                  0.865467   \n",
      "10      Word2Vec                  SVM                  0.881440   \n",
      "\n",
      "    Test Accuracy  Spam Recall        Confusion Matrix  \n",
      "0        0.930755     0.510067    [[959, 4], [73, 76]]  \n",
      "1        0.976619     0.906040  [[951, 12], [14, 135]]  \n",
      "2        0.980216     0.859060   [[962, 1], [21, 128]]  \n",
      "3        0.981115     0.885906   [[959, 4], [17, 132]]  \n",
      "4        0.935252     0.630872   [[946, 17], [55, 94]]  \n",
      "5        0.960432     0.718121   [[961, 2], [42, 107]]  \n",
      "6        0.957734     0.711409   [[959, 4], [43, 106]]  \n",
      "7        0.986511     0.926174   [[959, 4], [11, 138]]  \n",
      "8        0.918165     0.570470   [[936, 27], [64, 85]]  \n",
      "9        0.866007     0.000000    [[963, 0], [149, 0]]  \n",
      "10       0.892086     0.214765   [[960, 3], [117, 32]]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load cleaned dataset\n",
    "file_path = \"sms_cleaned.csv\"  # Ensure file is in the same directory\n",
    "sms_df = pd.read_csv(file_path)\n",
    "\n",
    "# Train-Test Split (80:20) with stratified sampling\n",
    "X = sms_df[\"cleaned_sms_message\"]\n",
    "y = sms_df[\"label\"]\n",
    "\n",
    "random_state = 189357722\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=random_state\n",
    ")\n",
    "\n",
    "# Define vectorizers\n",
    "vectorizers = {\n",
    "    \"Bag of Words\": CountVectorizer(),\n",
    "    \"TF-IDF\": TfidfVectorizer()\n",
    "}\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=[text.split() for text in X_train], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get average Word2Vec embeddings for a sentence\n",
    "def get_w2v_features(text, model, vector_size=100):\n",
    "    words = text.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(vector_size)\n",
    "\n",
    "# Get Word2Vec features for training & testing sets\n",
    "X_train_w2v = np.array([get_w2v_features(text, w2v_model) for text in X_train])\n",
    "X_test_w2v = np.array([get_w2v_features(text, w2v_model) for text in X_test])\n",
    "\n",
    "# Define classifiers\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion=\"gini\", max_depth=5, splitter=\"best\", random_state=random_state),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "    \"SVM\": SVC(kernel=\"linear\", probability=True, class_weight={\"ham\": 1, \"spam\": 2}, random_state=random_state)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate models using Bag of Words & TF-IDF\n",
    "for vec_name, vectorizer in vectorizers.items():\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train_vec, y_train)\n",
    "\n",
    "        # Cross-validation accuracy\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        cv_scores = cross_val_score(model, X_train_vec, y_train, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "        # Test set evaluation\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred, target_names=[\"ham\", \"spam\"], output_dict=True)\n",
    "\n",
    "        # Extract recall for spam class\n",
    "        spam_recall = class_report[\"spam\"][\"recall\"]\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Feature Model\": vec_name,\n",
    "            \"Classifier\": model_name,\n",
    "            \"Mean Train Accuracy (CV)\": np.mean(cv_scores),\n",
    "            \"Test Accuracy\": test_accuracy,\n",
    "            \"Spam Recall\": spam_recall,\n",
    "            \"Confusion Matrix\": conf_matrix\n",
    "        })\n",
    "\n",
    "# Train & Evaluate Word2Vec Models (Skip Naïve Bayes)\n",
    "for model_name, model in models.items():\n",
    "    if model_name == \"Naive Bayes\":\n",
    "        print(f\"Skipping {model_name} for Word2Vec (it does not support negative values).\")\n",
    "        continue  # Skip Naïve Bayes for Word2Vec\n",
    "    \n",
    "    model.fit(X_train_w2v, y_train)\n",
    "    \n",
    "    # Cross-validation accuracy\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    cv_scores = cross_val_score(model, X_train_w2v, y_train, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_pred = model.predict(X_test_w2v)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, target_names=[\"ham\", \"spam\"], output_dict=True)\n",
    "\n",
    "    # Extract recall for spam class\n",
    "    spam_recall = class_report[\"spam\"][\"recall\"]\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Feature Model\": \"Word2Vec\",\n",
    "        \"Classifier\": model_name,\n",
    "        \"Mean Train Accuracy (CV)\": np.mean(cv_scores),\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Spam Recall\": spam_recall,\n",
    "        \"Confusion Matrix\": conf_matrix\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display best model based on test accuracy\n",
    "best_model = results_df.sort_values(by=\"Test Accuracy\", ascending=False).iloc[0]\n",
    "print(\"\\nBest Model Performance:\")\n",
    "print(best_model)\n",
    "\n",
    "# Display all model results\n",
    "print(\"\\nAll Model Results:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
