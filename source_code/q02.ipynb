{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State = 42\n",
      "\n",
      "Class Distribution in Training and Test Sets:\n",
      "  Target Label  Train Count  Test Count\n",
      "0          ham         3847         963\n",
      "1         spam          598         149\n",
      "\n",
      "Proportion of ham to spam in training: 6.43\n",
      "Proportion of ham to spam in testing: 6.46\n",
      "\n",
      "BOW Model:> Train features shape: (4445, 4539)  Test features shape: (1112, 4539)\n",
      "Number of Terms Extracted (BoW): 4539\n",
      "\n",
      "Decision Tree Cross-Validation Accuracy (5-Fold): [0.91788526 0.9223847  0.92688414 0.92463442 0.92575928]\n",
      "Mean CV Accuracy: 0.9235095613048369\n",
      "\n",
      "Decision Tree Test Accuracy: 0.9262589928057554\n",
      "\n",
      "Confusion Matrix:\n",
      " [[956   7]\n",
      " [ 75  74]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.99      0.96       963\n",
      "        spam       0.91      0.50      0.64       149\n",
      "\n",
      "    accuracy                           0.93      1112\n",
      "   macro avg       0.92      0.74      0.80      1112\n",
      "weighted avg       0.93      0.93      0.92      1112\n",
      "\n",
      "\n",
      "Decision tree visualization saved as decision_tree.pdf\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# Load the cleaned dataset\n",
    "file_path = \"./sms_cleaned.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Set a fixed random state for reproducibility\n",
    "random_state = 42  # Fixed seed\n",
    "print(f'Random State = {random_state}')\n",
    "\n",
    "# Train-Test Split (80:20) with stratified sampling\n",
    "X = df[\"cleaned_sms_message\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "train_corpus, test_corpus, train_label, test_label = train_test_split(\n",
    "    np.array(X), np.array(y), test_size=0.20, stratify=y, shuffle=True, random_state=random_state\n",
    ")\n",
    "\n",
    "# Check class distribution in training and test sets\n",
    "trd = dict(Counter(train_label))\n",
    "tsd = dict(Counter(test_label))\n",
    "print(\"\\nClass Distribution in Training and Test Sets:\")\n",
    "print(pd.DataFrame([[key, trd[key], tsd[key]] for key in trd], \n",
    "                   columns=['Target Label', 'Train Count', 'Test Count']).sort_values(by=['Train Count'], ascending=False))\n",
    "\n",
    "print(\"\\nProportion of ham to spam in training:\", round(trd['ham'] / trd['spam'], 2))\n",
    "print(\"Proportion of ham to spam in testing:\", round(tsd['ham'] / tsd['spam'], 2))\n",
    "\n",
    "# Feature Engineering - Bag of Words (BoW)\n",
    "cv = CountVectorizer(min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "cv_test_features = cv.transform(test_corpus)\n",
    "\n",
    "print(\"\\nBOW Model:> Train features shape:\", cv_train_features.shape, \" Test features shape:\", cv_test_features.shape)\n",
    "print(\"Number of Terms Extracted (BoW):\", len(cv.get_feature_names_out()))\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, splitter=\"best\", random_state=random_state)\n",
    "clf.fit(cv_train_features, train_label)\n",
    "\n",
    "# Perform Cross-Validation on Training Data\n",
    "cv_scores = cross_val_score(clf, cv_train_features, train_label, cv=5)\n",
    "print(\"\\nDecision Tree Cross-Validation Accuracy (5-Fold):\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "y_pred = clf.predict(cv_test_features)\n",
    "\n",
    "test_accuracy = accuracy_score(test_label, y_pred)\n",
    "conf_matrix = confusion_matrix(test_label, y_pred)\n",
    "class_report = classification_report(test_label, y_pred, target_names=['ham', 'spam'])\n",
    "\n",
    "print(\"\\nDecision Tree Test Accuracy:\", test_accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "# Decision Tree Visualization\n",
    "dot_data = export_graphviz(\n",
    "    clf, out_file=None, feature_names=cv.get_feature_names_out(),\n",
    "    class_names=[\"ham\", \"spam\"], filled=True, rounded=True, special_characters=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")  # Saves as 'decision_tree.pdf'\n",
    "print(\"\\nDecision tree visualization saved as decision_tree.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
